# ğŸ§  NanoAgent â€” A 135M Parameter Agentic LLM

NanoAgent is a **135M parameter**, **8k context length**, open-source language model designed for **agentic tasks** such as **tool calling**, **instruction following**, and **lightweight reasoning**.  
Itâ€™s small enough (~135 MB in 8-bit) to run on **edge devices** like personal laptops, low-memory CPUs, and even wearables â€” yet smart enough to make tool calls, parse web information, and give structured answers.

---

## ğŸŒ Real-World Use Cases

- ğŸ•¹ï¸ **Runs on edge devices** â€” laptops, smartwatches, browsers, or CPU-only environments.  
- ğŸŒ **Parses and answers from the web** â€” supports tool calling to fetch real-time information.  
- ğŸ” **Answers recent questions** with live web search tools.  
- ğŸ’¬ **Continues conversations** â€” ideal for assistant or agent frameworks.  
- âš™ï¸ **Tool calling support** enables chaining multiple tools and parsing results to produce final answers.

---

## âœ¨ What NanoAgent Supports

| Capability                        | Description                                                                                     | Dataset Source                                                |
|------------------------------------|--------------------------------------------------------------------------------------------------|----------------------------------------------------------------|
| ğŸ’¬ Basic conversation              | Hi/hello, casual small talk                                                                     | `HuggingFaceTB/smoltalk`                                       |
| ğŸŒ Information retrieval           | e.g., *â€œHow to bake a cake?â€*, *â€œWeather in Torontoâ€* through web search. Extracts answers from information returned by tools (scraping/search)                        | Tool calling + Web Search                                     |
| ğŸ§° Tool calling                    | Single & multi-tool call with structured explanation                                            | `Locutusque/function-calling-chatml`, `Salesforce/xlam-function-calling-60k` |
| ğŸ§  Question decomposition          | Breaks complex questions into steps                                                             | `weijie210/gsm8k_decomposed`                                   |
| ğŸ§­ Question classification         | Identifies type of user query (e.g., fact, reasoning, instruction)                              | `microsoft/orca-agentinstruct-1M-v1`                           |
| ğŸ“ Following system prompts       | Responds properly to system-level instructions                                                  | Instruction datasets                                          |
| âœï¸ Writing emails and tasks       | Writes emails, structured messages                                                              | `HuggingFaceTB/smoltalk`                                      |

---

## ğŸ§ª Training Overview

- **Base model**: [`SmolLM2-135M-Instruct`](https://huggingface.co/HuggingFaceTB/SmolLM2-135M-Instruct)  
- **Fine-tuning method**: [Dynamic Fine-Tuning (DFT)](https://github.com/yongliang-wu/DFT/tree/master)  
- **Platform**: Apple Mac M1 (16 GB) â€” MLX framework

### ğŸ“š Datasets Used

| Dataset                                                                                  | Purpose                                                                 |
|-------------------------------------------------------------------------------------------|--------------------------------------------------------------------------|
| `microsoft/orca-agentinstruct-1M-v1`                                                      | Agentic tasks, classification, instruction following                     |
| `microsoft/orca-math-word-problems-200k`                                                 | Lightweight reasoning, word-level reasoning                              |
| `allenai/tulu-3-sft-personas-instruction-following`                                     | Instruction following with persona                                      |
| `xingyaoww/code-act`                                                                     | ReAct style reasoning and acting                                        |
| `m-a-p/Code-Feedback`                                                                    | Feedback alignment                                                      |
| `HuggingFaceTB/smoltalk`                                                                 | General conversation, system prompt handling                            |
| `HuggingFaceTB/smoltalk/apigen`                                                          | Tool calling stabilization                                             |
| `weijie210/gsm8k_decomposed`                                                             | Question decomposition                                                 |
| `Locutusque/function-calling-chatml`                                                     | Tool call response formatting                                          |
| `Salesforce/xlam-function-calling-60k`                                                   | Stronger function calling coverage                                     |
| `HuggingFaceTB/smoltalk2/SFT/smolagents_toolcalling_traces_think`                         | Web search, scraping, real-time reasoning                               |
| `Jofthomas/hermes-function-calling-thinking-V1`                                          | Tool calling support with thinking |
| `HuggingFaceTB/smoltalk/smol-magpie-ultra` | For python code writing |
---

## ğŸ§­ Key Explorations & Findings

- âœ‚ï¸ **Dataset deduplication** significantly improved performance by removing noisy or duplicate Q/As.  
 - âœ‚ï¸ **Shortening the responses** (casual response) and using shorter python code in training improved performance and reduce repeated token generation.
- ğŸ§® **Word-level reasoning** from `orca-math` enhanced the modelâ€™s ability to handle stepwise logic.  
- ğŸ§° Designing tool calling prompts using **six open-source tool calling datasets** resulted in stronger structured output generation.  
- ğŸŒ Tool calling integration enabled the model to **extract answers from parsed web data**, supporting up-to-date queries.  

---

## âš¡ Benchmark

| Metric / Task                      | SmolLM2-135M-Instruct | NanoAgent                |
|--------------------------------------|-------------------------|-----------------------------------|
| ğŸ§® **Parameters**                   | 135M                    | 135M                              |
| ğŸ“ **Context Length**               | 8k                      | 8k                                |
| ğŸ“Š **IFEval Score (Overall)**       | ---                    | ---                          |
| ğŸ§° **Tool Call Tasks**             | âŒ Not Supported        | âœ… Supported                      |
| ğŸ§­ **Instruction Following**       | ğŸŸ¡ Moderate             | ğŸŸ¢ Improved                       |
| ğŸ§  **Reasoning (Light)**          | ğŸŸ¡ Moderate             | ğŸŸ¡ Moderate                       |
| ğŸ“ **Training Method**            | Baseline (SFT)          | DFT + Agentic Finetuning         |
| ğŸ§ª **Strength**                   | Instruction following   | Tool call ability + structured outputs |
| âš ï¸ **Limitations**               | No tool calling         | Occasional tool errors, still beta |

> *Scores measured using exact match across instruction-following and tool-calling tasks. Tool call accuracy reflects structured format compliance.*

---

## ğŸ§­ Roadmap

- [ ] ğŸ“Š Benchmark more agentic tasks  
- [ ] ğŸ§  Explore GRPO for tool calling improvement  
- [ ] ğŸ”€ Experiment with weight merging  
- [ ] ğŸ§ª Evaluate multi-turn tool chaining  
- [ ] ğŸ§¹ Further refine datasets for stability

---

